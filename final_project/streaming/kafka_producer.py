"""
ChÆ°Æ¡ng trÃ¬nh mÃ´ phá»ng streaming - gá»­i dá»¯ liá»‡u vÃ o Kafka
Äá»c dá»¯ liá»‡u tá»« HDFS
"""
import json
import os
import time
import pandas as pd
from kafka import KafkaProducer
from kafka.errors import NoBrokersAvailable
import sys
import subprocess
import tempfile

def read_from_hdfs(hdfs_path):
    """
    Äá»c file CSV tá»« HDFS vÃ  tráº£ vá» DataFrame
    
    Args:
        hdfs_path: ÄÆ°á»ng dáº«n HDFS (vÃ­ dá»¥: hdfs://worker1:8020/bigdata/house_prices/streaming_data.csv)
    
    Returns:
        pandas.DataFrame
    """
    # Táº¡o file táº¡m vá»›i tÃªn unique Ä‘á»ƒ trÃ¡nh conflict
    import uuid
    temp_path = os.path.join(tempfile.gettempdir(), f"hdfs_streaming_{uuid.uuid4().hex}.csv")
    
    try:
        # XÃ³a file táº¡m náº¿u Ä‘Ã£ tá»“n táº¡i (Ä‘á»ƒ Ä‘áº£m báº£o)
        if os.path.exists(temp_path):
            os.unlink(temp_path)
        
        # Sá»­ dá»¥ng hdfs dfs -get vá»›i flag -f Ä‘á»ƒ force overwrite
        cmd = ['hdfs', 'dfs', '-get', '-f', hdfs_path, temp_path]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        
        if result.returncode != 0:
            # Náº¿u flag -f khÃ´ng Ä‘Æ°á»£c há»— trá»£, thá»­ láº¡i khÃ´ng cÃ³ flag
            if '-f' in result.stderr or 'Unknown command' in result.stderr:
                # XÃ³a file náº¿u tá»“n táº¡i vÃ  thá»­ láº¡i khÃ´ng cÃ³ -f
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                cmd = ['hdfs', 'dfs', '-get', hdfs_path, temp_path]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                raise Exception(
                    f"KhÃ´ng thá»ƒ Ä‘á»c file tá»« HDFS: {hdfs_path}\n"
                    f"Error: {result.stderr}\n"
                    f"Command: {' '.join(cmd)}"
                )
        
        # Kiá»ƒm tra file Ä‘Ã£ Ä‘Æ°á»£c download chÆ°a
        if not os.path.exists(temp_path):
            raise Exception(f"File táº¡m khÃ´ng Ä‘Æ°á»£c táº¡o: {temp_path}")
        
        # Äá»c file CSV tá»« local
        df = pd.read_csv(temp_path)
        print(f"âœ“ ÄÃ£ Ä‘á»c {len(df)} dÃ²ng tá»« HDFS: {hdfs_path}")
        
        return df
    
    finally:
        # XÃ³a file táº¡m
        if os.path.exists(temp_path):
            try:
                os.unlink(temp_path)
            except Exception:
                pass  # Ignore errors khi xÃ³a file

def create_producer(max_retries=10):
    """Táº¡o Kafka producer vá»›i retry logic, dÃ¹ng hostname hoáº·c env."""
    # Cho phÃ©p cáº¥u hÃ¬nh qua env Ä‘á»ƒ trÃ¡nh hard-code IP
    # Default lÃ  localhost:9092 (cháº¡y trÃªn mÃ¡y Kafka)
    bootstrap = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
    servers = [s.strip() for s in bootstrap.split(",") if s.strip()]

    for i in range(max_retries):
        try:
            producer = KafkaProducer(
                bootstrap_servers=servers,
                value_serializer=lambda x: json.dumps(x).encode('utf-8'),
                api_version=(2, 5, 0)
            )
            print(f"âœ“ ÄÃ£ káº¿t ná»‘i Ä‘áº¿n Kafka broker: {servers}")
            return producer
        except NoBrokersAvailable:
            if i < max_retries - 1:
                print(f"â³ Äang chá» Kafka khá»Ÿi Ä‘á»™ng... (thá»­ láº§n {i+1}/{max_retries})")
                time.sleep(5)
            else:
                print("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i Ä‘áº¿n Kafka sau nhiá»u láº§n thá»­")
                raise

def send_streaming_data(interval=2, num_records=None):
    """
    Gá»­i dá»¯ liá»‡u streaming vÃ o Kafka
    
    Args:
        interval: Khoáº£ng thá»i gian giá»¯a cÃ¡c láº§n gá»­i (giÃ¢y)
        num_records: Sá»‘ lÆ°á»£ng báº£n ghi gá»­i (None = gá»­i táº¥t cáº£)
    """
    # Äá»c dá»¯ liá»‡u tá»« HDFS (on Nole3)
    # CÃ³ thá»ƒ override báº±ng environment variable
    hdfs_namenode = os.getenv("HDFS_NAMENODE", "hdfs://nole3:8020")
    hdfs_data_path = os.getenv(
        "HDFS_STREAMING_DATA_PATH",
        f"{hdfs_namenode}/bigdata/house_prices/streaming_data.csv"
    )
    
    print(f"ğŸ“‚ Äá»c dá»¯ liá»‡u tá»« HDFS: {hdfs_data_path}")
    df = read_from_hdfs(hdfs_data_path)
    
    if num_records:
        df = df.head(num_records)
    
    print("=" * 60)
    print("KAFKA PRODUCER - MÃ” PHá»NG STREAMING")
    print("=" * 60)
    print(f"Sá»‘ lÆ°á»£ng báº£n ghi sáº½ gá»­i: {len(df)}")
    print(f"Khoáº£ng thá»i gian: {interval} giÃ¢y/báº£n ghi")
    print(f"Topic: house-prices-input")
    print("=" * 60)
    
    # Táº¡o producer
    producer = create_producer()
    
    try:
        for idx, row in df.iterrows():
            # Táº¡o message (khÃ´ng bao gá»“m target - Ä‘á»ƒ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n)
            message = {
                'id': idx,
                'MedInc': float(row['MedInc']),
                'HouseAge': float(row['HouseAge']),
                'AveRooms': float(row['AveRooms']),
                'AveBedrms': float(row['AveBedrms']),
                'Population': float(row['Population']),
                'AveOccup': float(row['AveOccup']),
                'Latitude': float(row['Latitude']),
                'Longitude': float(row['Longitude']),
                'actual_price': float(row['target'])  # GiÃ¡ thá»±c táº¿ Ä‘á»ƒ so sÃ¡nh
            }
            
            # Gá»­i vÃ o Kafka
            producer.send('house-prices-input', value=message)
            
            print(f"ğŸ“¤ ÄÃ£ gá»­i báº£n ghi {idx+1}/{len(df)} | "
                  f"MedInc={message['MedInc']:.2f} | "
                  f"Actual Price=${message['actual_price']*100:.2f}K")
            
            time.sleep(interval)
        
        producer.flush()
        print("\nâœ“ ÄÃ£ gá»­i táº¥t cáº£ dá»¯ liá»‡u!")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ÄÃ£ dá»«ng streaming")
    finally:
        producer.close()
        print("âœ“ ÄÃ£ Ä‘Ã³ng producer")

if __name__ == "__main__":
    # CÃ³ thá»ƒ truyá»n tham sá»‘ tá»« command line
    interval = float(sys.argv[1]) if len(sys.argv) > 1 else 2
    num_records = int(sys.argv[2]) if len(sys.argv) > 2 else None
    
    send_streaming_data(interval=interval, num_records=num_records)