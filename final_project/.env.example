# ============================================
# HDFS Configuration
# ============================================
HDFS_NAMENODE=hdfs://nole3:8020
HDFS_TRAIN_DATA_PATH=hdfs://nole3:8020/bigdata/house_prices/train_data.csv
HDFS_STREAMING_DATA_PATH=hdfs://nole3:8020/bigdata/house_prices/streaming_data.csv
HDFS_MODEL_PATH=hdfs://nole3:8020/bigdata/house_prices/model

# ============================================
# Kafka Configuration
# ============================================
KAFKA_BOOTSTRAP_SERVERS=nole2:9092
KAFKA_INPUT_TOPIC=house-prices-input
KAFKA_OUTPUT_TOPIC=house-prices-output

# ============================================
# Spark Configuration
# ============================================
SPARK_MASTER=spark://nole1:7077
SPARK_HOME=/home/user/spark-4.0.0-bin-hadoop3

# ============================================
# RabbitMQ/Celery Configuration
# ============================================
CELERY_BROKER_URL=pyamqp://guest@airflow-master//
CELERY_RESULT_BACKEND=rpc://

# ============================================
# Airflow Configuration
# ============================================
AIRFLOW_HOME=/home/user/airflow
AIRFLOW__CORE__EXECUTOR=CeleryExecutor
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost/airflow

# ============================================
# Node/Queue Mapping
# ============================================
KAFKA_QUEUE=nole2
SPARK_QUEUE=nole1
HADOOP_QUEUE=nole3

# ============================================
# Network Configuration
# ============================================
# IP addresses for reference (use hostnames in code)
NOLE1_IP=192.168.80.165
NOLE2_IP=192.168.80.51
NOLE3_IP=192.168.80.178
