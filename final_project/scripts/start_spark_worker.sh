#!/bin/bash
# Script Ä‘á»ƒ start Celery worker cho Spark trÃªn mÃ¡y Spark
# Usage: ./start_spark_worker.sh <HOSTNAME_AIRFLOW>

if [ $# -ne 1 ]; then
    echo "Usage: $0 <HOSTNAME_AIRFLOW>"
    echo "Example: $0 airflow-master"
    exit 1
fi

HOSTNAME_AIRFLOW=$1
# Tá»± Ä‘á»™ng detect project directory tá»« script location
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(cd "$SCRIPT_DIR/.." && pwd)"

echo "=========================================="
echo "Start Celery Worker cho Spark"
echo "=========================================="
echo "RabbitMQ Host: $HOSTNAME_AIRFLOW"
echo "Queue: spark"
echo ""

# Set broker URL
export CELERY_BROKER_URL="amqp://guest:guest@${HOSTNAME_AIRFLOW}:5672//"

# Test káº¿t ná»‘i
echo "Test káº¿t ná»‘i tá»›i RabbitMQ..."
if ! timeout 5 bash -c "echo > /dev/tcp/${HOSTNAME_AIRFLOW}/5672" 2>/dev/null; then
    echo "âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i $HOSTNAME_AIRFLOW:5672"
    echo "Kiá»ƒm tra:"
    echo "  1. /etc/hosts Ä‘Ã£ cÃ³ entry cho $HOSTNAME_AIRFLOW chÆ°a?"
    echo "  2. RabbitMQ Ä‘ang cháº¡y trÃªn mÃ¡y Airflow chÆ°a?"
    echo "  3. Firewall Ä‘Ã£ má»Ÿ port 5672 chÆ°a?"
    exit 1
fi

echo "âœ“ Káº¿t ná»‘i thÃ nh cÃ´ng!"

# âœ… FIX: Tá»± Ä‘á»™ng detect vÃ  set SPARK_HOME
if [ -z "$SPARK_HOME" ]; then
    # Thá»­ cÃ¡c vá»‹ trÃ­ thÃ´ng thÆ°á»ng
    if [ -d "/opt/spark" ] && [ -f "/opt/spark/bin/spark-submit" ]; then
        export SPARK_HOME="/opt/spark"
    elif [ -d "$HOME/spark" ] && [ -f "$HOME/spark/bin/spark-submit" ]; then
        export SPARK_HOME="$HOME/spark"
    elif [ -d "/usr/local/spark" ] && [ -f "/usr/local/spark/bin/spark-submit" ]; then
        export SPARK_HOME="/usr/local/spark"
    elif [ -d "/opt/spark-4.0.0-bin-hadoop3" ]; then
        export SPARK_HOME="/opt/spark-4.0.0-bin-hadoop3"
    fi
fi

if [ -n "$SPARK_HOME" ]; then
    export PATH="$SPARK_HOME/bin:$PATH"
    echo "âœ“ SPARK_HOME: $SPARK_HOME"
    echo "âœ“ spark-submit: $(which spark-submit 2>/dev/null || echo 'not in PATH')"
else
    echo "âš ï¸  SPARK_HOME not set, script will try to find spark-submit automatically"
fi

# Chuyá»ƒn Ä‘áº¿n thÆ° má»¥c project
cd "$PROJECT_DIR" || {
    echo "âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: $PROJECT_DIR"
    echo "Vui lÃ²ng sá»­a PROJECT_DIR trong script nÃ y"
    exit 1
}

# âœ… FIX: Kiá»ƒm tra vÃ  cÃ i Ä‘áº·t Python dependencies
echo ""
echo "ğŸ“¦ Kiá»ƒm tra Python dependencies..."
if [ -f "$PROJECT_DIR/requirements.txt" ]; then
    # Kiá»ƒm tra numpy (dependency quan trá»ng nháº¥t cho PySpark ML)
    if ! python3 -c "import numpy" 2>/dev/null; then
        echo "âš ï¸  numpy chÆ°a Ä‘Æ°á»£c cÃ i, Ä‘ang cÃ i Ä‘áº·t dependencies tá»« requirements.txt..."
        pip3 install --user -r "$PROJECT_DIR/requirements.txt" 2>&1 | tail -10 || {
            echo "âš ï¸  CÃ i Ä‘áº·t dependencies cÃ³ thá»ƒ Ä‘Ã£ tháº¥t báº¡i hoáº·c má»™t sá»‘ Ä‘Ã£ Ä‘Æ°á»£c cÃ i"
            echo "   Kiá»ƒm tra: pip3 list | grep -E 'numpy|pandas|scikit-learn'"
        }
    else
        echo "âœ“ Python dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t (numpy found)"
    fi
else
    echo "âš ï¸  KhÃ´ng tÃ¬m tháº¥y requirements.txt, cÃ i Ä‘áº·t numpy cÆ¡ báº£n..."
    pip3 install --user numpy>=1.21.0 2>&1 | tail -5 || echo "âš ï¸  CÃ i Ä‘áº·t numpy cÃ³ thá»ƒ Ä‘Ã£ tháº¥t báº¡i"
fi

# Start worker
echo ""
echo "Äang start Celery worker..."
celery -A mycelery.system_worker worker \
  -Q spark \
  -n spark@%h \
  --loglevel=INFO

