#!/bin/bash

# Script ki·ªÉm tra Spark Workers v√† d·ª´ng workers kh√¥ng c·∫ßn thi·∫øt

echo "üîç Ki·ªÉm tra Spark Workers ƒëang ch·∫°y..."
echo ""

# Ki·ªÉm tra tr√™n m√°y hi·ªán t·∫°i
echo "üìç M√°y hi·ªán t·∫°i: $(hostname)"
echo "IP: $(hostname -I | awk '{print $1}')"
echo ""

# Ki·ªÉm tra Spark workers
echo "üîé T√¨m Spark Workers:"
ps aux | grep -i "spark.*worker" | grep -v grep || echo "  Kh√¥ng t√¨m th·∫•y Spark worker tr√™n m√°y n√†y"
echo ""

# Ki·ªÉm tra Java processes
echo "‚òï Java processes (c√≥ th·ªÉ l√† Spark workers):"
jps 2>/dev/null | grep -i worker || echo "  Kh√¥ng t√¨m th·∫•y worker process"
echo ""

# Ki·ªÉm tra Spark Master UI
echo "üåê Ki·ªÉm tra Spark Master UI:"
SPARK_MASTER="worker3"
echo "  URL: http://${SPARK_MASTER}:8080"
echo ""

# Ki·ªÉm tra workers qua API (n·∫øu c√≥ curl)
if command -v curl &> /dev/null; then
    echo "üìä Workers t·ª´ Spark Master API:"
    curl -s "http://${SPARK_MASTER}:8080/api/v1/applications" 2>/dev/null | python3 -m json.tool 2>/dev/null | head -20 || echo "  Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Spark Master"
    echo ""
fi

# H∆∞·ªõng d·∫´n d·ª´ng workers
echo "‚ö†Ô∏è  N·∫øu c√≥ Spark worker tr√™n m√°y Airflow (192.168.80.147):"
echo "  1. SSH v√†o m√°y Airflow:"
echo "     ssh user@192.168.80.147"
echo ""
echo "  2. D·ª´ng Spark workers:"
echo "     pkill -f 'spark.*worker'"
echo "     # Ho·∫∑c"
echo "     jps | grep Worker | awk '{print \$1}' | xargs kill"
echo ""
echo "  3. N·∫øu d√πng docker-compose:"
echo "     cd ~/docker-spark && docker-compose down"
echo ""

